---
layout: post
title: Week 2
---

## Literature Review on Learning Theory

// Knowledge Change Processes in each Mode
 
Continuing where I've left off, 

## Background work on TMKL2

// Understanding actual diagram of each elements

//Looking at previous implementation with GAIA

// Looking at a worked model

// Working with DI-IVY Team

## Literature Review on Generative AI
During my literature review, technical background on generative AI (Gen AI) architecture is needed in order for me to understand more advanced topics such as taxonomy of XAI techniques, its challenges and future research agenda. I learned about how generative AI is the next level of AI, coming from AI that classifies to an AI that creates. Additionally, I reviewed several Gen AI methods such as transformers, diffusion models, Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) from the paper titled **"Explainable Generative AI (GenXAI): A Survey, Conceptualization, and Research Agenda"** by J. Schneider.

Transformer models, prevalent in LLMs such as GPT models, are known for their flexibility due to their reliance on extensive training data. While transformer implementations can vary, a fundamental structure typically consists of an encoder and a decoder, each processing input tokens. Encoders utilize vector embeddings to extract information from their input data, with embeddings representing tokens in a latent space. Tokens in this sense is a way for a computer to understand and manipulate words which captures human semantic understanding.  Additionally, positional encoding, an important component of attention-based encoding, provides information about the relative positions of tokens in the input sequence, which help capture sequential relationships. Then, these are processed through layers of self-attention mechanisms to be fed into a feedforward network for further processing. Once the encoding phase is complete, the decoder generates the output sequence from the encoded information from the encoder. Decoding involves an autoregressive process where the model predicts one token at a time, based on the previously generated tokens. This process continues until the desired output sequence is generated. 

Meanwhile, diffusion models are used by generative AI to create images. Its main aim is to learn to reconstruct noisy data. It operates in two phases: the forward pass, where input distortion happens, and the reverse pass, where the output image is generated.  During the forward pass, a technique called Denoising Diffusion Probabilistic Model (DDPM) acts like a Markov chain. This means that only the current input is important for determining the next one. The model distorts the input by adding noise until it resembles a specific distribution, like a Gaussian distribution, which is commonly used in image generation. In the reverse pass, the model is supposed to generate images that match the true data distribution.

The next two Gen AI methods are more widely used and primarily designed for generative modeling: Variational Autoencoders (VAEs) and Generative adversarial Networks (GANs). Both methods generate new data that resembles a given training datasets, both use the concept of latent space and both primarily learns through a probabilistic framework.

Variational Autoencoders (VAEs) aims to generate an output similar to what it was trained on by organizing the data of the input into a hidden space or what they mathematically call 'latent space'. The latent space acts as a blueprint based on the distribution of the data. The latent space representation is explicitly modeled through the encoder-decoder architecture. From here, VAEs learn a probabilistic model of the data; then, the output is generated from this learned distribution called 'sample generation'.

GAN has two key players: generator and discriminator. The generator creates an output based on a random vector, while the discriminator acts as an adversary, distinguishing between the generated output and real samples from the true data distribution.  GANs implicitly learn the data distribution through this adversarial training process. Additionally in GANs, this latent space is learned implicitly through the generator and discriminator networks. 

## Review on LangChain Language Protocol

I started on this [documentation] (https://python.langchain.com/v0.1/docs/expression_language/). 

## DREAM Housekeeping Work

// DREAM Kick off meeting with all the participants


